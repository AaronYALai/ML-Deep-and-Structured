{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "start_time = time.clock()\n",
    "#The map from labels to integers\n",
    "lab_index = dict([['aa', 0], ['ae', 1], ['ah', 2], ['ao', 3], ['aw', 4], ['ax', 5], ['ay', 6], ['b', 7], ['ch', 8], \n",
    "               ['cl', 9], ['d', 10], ['dh', 11], ['dx', 12], ['eh', 13], ['el', 14], ['en', 15], ['epi', 16], \n",
    "               ['er', 17], ['ey', 18], ['f', 19], ['g', 20], ['hh', 21], ['ih', 22], ['ix', 23], ['iy', 24], \n",
    "               ['jh', 25], ['k', 26], ['l', 27], ['m', 28], ['ng', 29], ['n', 30], ['ow', 31], ['oy', 32], ['p', 33], \n",
    "               ['r', 34], ['sh', 35], ['sil', 36], ['s', 37], ['th', 38], ['t', 39], ['uh', 40], ['uw', 41], ['vcl', 42],\n",
    "               ['v', 43], ['w', 44], ['y', 45], ['zh', 46], ['z', 47]])\n",
    "\n",
    "def make_vector_sequence(Data,TID):\n",
    "    \"\"\"Concatenate vectors into single sequence of an utterance\"\"\"\n",
    "    Dat = defaultdict(list)\n",
    "    Number = {}; n = 0; old = ''\n",
    "    for i in range(len(Data)):\n",
    "        ID = '_'.join(TID[i].split('_')[:2])\n",
    "        Dat[ID].append(Data[i])\n",
    "        if ID != old:\n",
    "            Number[n] = ID\n",
    "            n += 1\n",
    "            old = ID\n",
    "    return Dat, Number\n",
    "\n",
    "def Map_label(n):\n",
    "    \"\"\"Return label an integer(0-47) corresponds to\"\"\"\n",
    "    for key,val in lab_index.items():\n",
    "        if val == n:\n",
    "            return key\n",
    "    print(\"Worng!\")\n",
    "\n",
    "mapp = open('48_39.map').readlines()\n",
    "mapping = {}\n",
    "for line in mapp:\n",
    "    line = line.strip().split('\\t')\n",
    "    mapping[line[0]] = line[1]\n",
    "\n",
    "Mapp = open('48_idx_chr.map_b').readlines()\n",
    "Map = {}\n",
    "for line in Mapp:\n",
    "    line = line.strip().split(' ')\n",
    "    word,_ = line[0].split('\\t')\n",
    "    Map[word] = line[-1]\n",
    "\n",
    "file = open('train.lab')\n",
    "TrainLab = {}; ID = ''; lab = []\n",
    "TrainY = {}; seq = ''\n",
    "for line in file:\n",
    "    line = line.strip().split(',')\n",
    "    SeqID = '_'.join(line[0].split('_')[:2])\n",
    "    idx = Map[mapping[line[1]]]\n",
    "    \n",
    "    if SeqID != ID:\n",
    "        TrainLab[ID] = lab\n",
    "        lab = []\n",
    "        TrainY[ID] = seq[2:-3]\n",
    "        seq = ''\n",
    "        \n",
    "    lab.append(line[1])\n",
    "    if len(seq)==0 or idx!=seq[-2]:\n",
    "        seq = seq+idx+' '\n",
    "    ID = SeqID\n",
    "    \n",
    "TrainLab[ID] = lab\n",
    "TrainY[ID] = seq[2:-3]\n",
    "file.close()\n",
    "\n",
    "Train = np.load('prob_t.npz')\n",
    "Train = Train[Train.files[0]]\n",
    "TrID = np.load('TrainID.npz')\n",
    "TrainID = TrID[TrID.files[0]][0]\n",
    "\n",
    "TrainX , Train_Num = make_vector_sequence(Train,TrainID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, using 5.166637 seconds\n"
     ]
    }
   ],
   "source": [
    "def Transition_proba(index):\n",
    "    '''Calculate the transition probability matrix'''\n",
    "    Transition = np.zeros((48,48))\n",
    "    for ind in index:\n",
    "        To = ''; From = ''; c = 0\n",
    "        for cha in TrainLab[Train_Num[ind]]:\n",
    "            To = cha\n",
    "            c = c+1 if From == To else 0\n",
    "            if len(From) != 0:\n",
    "                Transition[lab_index[From]][lab_index[To]] += 1\n",
    "            From = cha\n",
    "    #Smoothing        \n",
    "    Transition = np.array(list(map(lambda x: np.log(x+2),Transition)))\n",
    "    Trans_prob = (Transition.T/np.sum(Transition,axis=1)).T\n",
    "    return Trans_prob\n",
    "\n",
    "def toidx(seq,c):\n",
    "    '''Transform the phoneme sequences into required format'''\n",
    "    out = []; now = -1; count = 0\n",
    "    for n in seq:\n",
    "        if n != now:\n",
    "            if count >= c:\n",
    "                if len(out)==0 or out[-1]!=now:\n",
    "                    out.append(now)\n",
    "            now = n\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "    if count >= c:\n",
    "        out.append(now)\n",
    "\n",
    "    Str = ''\n",
    "    for i in out:\n",
    "        Str = Str + Map[i]\n",
    "    return Str[1:-1]\n",
    "\n",
    "def Voting(predicts):\n",
    "    '''Blend the models uniformly'''\n",
    "    result = []\n",
    "    for i in range(len(predicts[0])):\n",
    "        row = []\n",
    "        for j in range(len(predicts[0][i])):\n",
    "            l = []\n",
    "            for k in range(len(predicts)):\n",
    "                l.append(predicts[k][i][j])\n",
    "            row.append(Counter(l).most_common()[0][0])\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def edit(r,h):\n",
    "    \"\"\"edit distance\"\"\"\n",
    "    r = r.split(); h = h.split()\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "                if i == 0:\n",
    "                        d[0][j] = j\n",
    "                elif j == 0:\n",
    "                        d[i][0] = i\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "            for j in range(1, len(h)+1):\n",
    "                    if r[i-1] == h[j-1]:\n",
    "                        d[i][j] = d[i-1][j-1]\n",
    "                    else:\n",
    "                        substitution = d[i-1][j-1] + 1\n",
    "                        insertion    = d[i][j-1] + 1\n",
    "                        deletion     = d[i-1][j] + 1\n",
    "                        d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "def score(seq,ind,c):\n",
    "    \"\"\"Calculate the edit distance on validation set\"\"\"\n",
    "    out = []; now = -1; count = 0\n",
    "    for n in seq:\n",
    "        if n != now:\n",
    "            if count >= c:\n",
    "                if len(out)==0 or out[-1]!=now:\n",
    "                    out.append(now)\n",
    "            now = n\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "    if count >= c:\n",
    "        out.append(now)\n",
    "\n",
    "    Str = ''\n",
    "    for i in out:\n",
    "        Str = Str + Map[i] + ' '\n",
    "    return edit(TrainY[Train_Num[ind]],Str[2:-3])\n",
    "\n",
    "print(\"Data loaded, using %f seconds\"%(time.clock()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start predicting...\")\n",
    "\n",
    "Test = np.load('RNN.npz')\n",
    "Test = Test[Test.files[0]]\n",
    "TID = np.load('TestID.npz')\n",
    "TestID = TID[TID.files[0]][0]\n",
    "\n",
    "TestD , Test_Num = make_vector_sequence(Test,TestID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has edit distance 6.8361 on the validation set.\n"
     ]
    }
   ],
   "source": [
    "TestD , Test_Num = make_vector_sequence(Test,TestID)\n",
    "Predict = {}\n",
    "Valid = {}\n",
    "Valid_ind = np.random.choice(len(Train_Num),len(Test_Num),replace=False)\n",
    "\n",
    "duration = 3\n",
    "for w in range(1): #change this when doing bagging\n",
    "    Seq_Pre = []\n",
    "    Val_Pre = []\n",
    "    Trans_prob = Transition_proba(list(range(3696))) #np.random.choice(3696,3696)\n",
    "    for z in range(len(Test_Num)): \n",
    "        Seq = TestD[Test_Num[z]]\n",
    "        VSeq = TrainX[Train_Num[Valid_ind[z]]]\n",
    "        prob = np.ones((48,))/48\n",
    "        Vprob = np.ones((48,))/48\n",
    "        predict = defaultdict(list)\n",
    "        Vpredict = defaultdict(list)\n",
    "        for l in Seq:\n",
    "            P = prob*(l**duration)*Trans_prob.T \n",
    "            prob = np.max(P,axis=1)\n",
    "            Arg = np.argmax(P,axis=1)\n",
    "            for i in range(48):\n",
    "                predict[i].append(mapping[Map_label(Arg[i])])\n",
    "\n",
    "            if min(prob) <= 10**(-20): #Prevent probabilities from underflowing\n",
    "                prob = prob*(10**15)\n",
    "\n",
    "        for l in VSeq:\n",
    "            P = Vprob*(l**duration)*Trans_prob.T #l = emission prob.\n",
    "            Vprob = np.max(P,axis=1)\n",
    "            Arg = np.argmax(P,axis=1)\n",
    "            for i in range(48):\n",
    "                Vpredict[i].append(mapping[Map_label(Arg[i])])\n",
    "\n",
    "            if min(Vprob) <= 10**(-20):\n",
    "                Vprob = Vprob*(10**15)\n",
    "\n",
    "        Seq_Pre.append(predict[np.argmax(prob)])\n",
    "        Val_Pre.append(Vpredict[np.argmax(Vprob)])\n",
    "    Predict[w] = Seq_Pre\n",
    "    Valid[w] = Val_Pre\n",
    "\n",
    "Valid_seq = Valid[0]\n",
    "Val = np.mean([score(Valid_seq[ind],val,3) for ind,val in enumerate(Valid_ind)])\n",
    "print(\"The model has edit distance %.4f on the validation set.\"%(Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hIwLAJUaIDBLNrDwLMwQU',\n",
       " 'tbLKsFLuwDBPJLIwBULHwLyNwKr',\n",
       " 'wLJcQrUtICBgLcQyDwLMywQLHrLHwcJwDrJLMnLMtrvrIFwLABymrKnLH',\n",
       " 'KyJBwOLMwDJLHIwEvrbELABaDcJLMyLHJBFLH',\n",
       " 'cBCwDcCJFQraSwrLAwDatwDLhytBnDUwyD',\n",
       " 'TcDLiwBLkIwDKOmcQaGmwLAJLhFKrLMwLADLMsLzwJLkwUyUcwJ',\n",
       " 'SnlrLHIyNLAcBaKwUrQwrITPJtBnDJybmB',\n",
       " 'HbDLuwLJLMIgQyEBnJDUaDLNrULMsU',\n",
       " 'vwJULAbLMwDFJLMwDcDvnbLurLkwDwULHymwtBLhPLMJLaISaIDwDKbLhy',\n",
       " 'lwQIyUJwUtrlwJLMgQJyDLtPBwKDeFB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for p in Predict[0]:  #Voting(Predict)\n",
    "    output.append(toidx(p,3))\n",
    "output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'ah', 'ah', 'ah', 'ah', 'ah', 'ah', 'ah', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'l', 'l', 'l', 'l', 'l', 'l', 'l', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'ey', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'w', 'w', 'w', 'ih', 'ih', 'ih', 'sil', 'sil', 'sil', 'sil', 'd', 'd', 'd', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'iy', 'iy', 'iy', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'ah', 'ah', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 't', 't', 't', 't', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'eh', 'aa', 'aa', 'aa', 'aa', 'aa', 'eh', 'eh', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'er', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil', 'sil']\n"
     ]
    }
   ],
   "source": [
    "print(Predict[0][np.random.choice(592)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done. Using 91.1830 seconds\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csvfile = open('HMM_RNN.csv','w',newline='')\n",
    "write = csv.writer(csvfile, delimiter=',')\n",
    "write.writerow(['id','phone_sequence'])\n",
    "\n",
    "for i in range(len(Test_Num)):\n",
    "    write.writerow([Test_Num[i],output[i]])\n",
    "\n",
    "csvfile.close()    \n",
    "print(\"All Done. Using %.4f seconds\"%(time.clock()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('RNN.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(Predict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Future work: Conditional Random Field and Structured SVM\n",
    "def psi(X,y):\n",
    "    vec = np.zeros((48,48))\n",
    "    trans = np.zeros((48,48))\n",
    "    From = -1; To = -1\n",
    "    for ind,val in enumerate(X):\n",
    "        vec[y[ind]]+= val\n",
    "        To = y[ind]\n",
    "        if From >= 0:\n",
    "            trans[From][To]+=1\n",
    "        From = y[ind]\n",
    "    return np.ravel(np.concatenate((vec,trans)))\n",
    "\n",
    "X = TrainD[Train_Num[i]]\n",
    "y = [lab_index[i] for i in TrainLab[Train_Num[i]]]\n",
    "T = psi(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
