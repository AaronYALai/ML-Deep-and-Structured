{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Id,Prediction\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "File = open('Predicts.csv')\n",
    "Raw = File.readlines()\n",
    "File.close()\n",
    "Raw.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'hh',\n",
       "  'iy',\n",
       "  'iy',\n",
       "  'iy',\n",
       "  'iy',\n",
       "  'iy',\n",
       "  'uw',\n",
       "  'uw',\n",
       "  'iy',\n",
       "  'iy',\n",
       "  'w',\n",
       "  'w',\n",
       "  'w',\n",
       "  'w',\n",
       "  'w',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'ih',\n",
       "  'ih',\n",
       "  'ih',\n",
       "  'ih',\n",
       "  'ih',\n",
       "  'ih',\n",
       "  'ow',\n",
       "  'ow',\n",
       "  'ow',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'ah',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'ah',\n",
       "  'ah',\n",
       "  'ow',\n",
       "  'ah',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aw',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'ah',\n",
       "  'ah',\n",
       "  'l',\n",
       "  'sil',\n",
       "  'k',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'aa',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'r',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'ae',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'eh',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'l',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'r',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'er',\n",
       "  'm',\n",
       "  'ay',\n",
       "  'ay',\n",
       "  'er',\n",
       "  'er',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil',\n",
       "  'sil'],\n",
       " 'fadg0_si1279')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "Data = defaultdict(list)\n",
    "Number = {}\n",
    "\n",
    "n = 0; old = ''\n",
    "for line in Raw:\n",
    "    ID,cha = line.strip().split(',')\n",
    "    ID = '_'.join(ID.split('_')[:2])\n",
    "    Data[ID].append(cha)\n",
    "    if ID != old:\n",
    "        Number[n] = ID\n",
    "        n += 1\n",
    "        old = ID\n",
    "        \n",
    "        \n",
    "Data['fjmg0_sx11'], Number[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'hh',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aw',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'ah',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'aa',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'eh',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'ay',\n",
       " 'ay',\n",
       " 'er',\n",
       " 'er',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decide(value,i):\n",
    "    if value[i-1] == value[i+1]:\n",
    "        return True\n",
    "    elif value[i]!= value[i+1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "for key,value in Data.items():\n",
    "    for i in range(1,len(value)-1):\n",
    "        if decide(value,i) and value[i]!= value[i-1]:\n",
    "            value[i] = value[i-1]\n",
    "    Data[key] = value\n",
    "    \n",
    "Data['fjmg0_sx11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'hh',\n",
       " 'iy',\n",
       " 'uw',\n",
       " 'iy',\n",
       " 'w',\n",
       " 'l',\n",
       " 'ih',\n",
       " 'ow',\n",
       " 'l',\n",
       " 'ah',\n",
       " 'l',\n",
       " 'ae',\n",
       " 'aw',\n",
       " 'aa',\n",
       " 'ah',\n",
       " 'aa',\n",
       " 'er',\n",
       " 'r',\n",
       " 'ae',\n",
       " 'eh',\n",
       " 'er',\n",
       " 'l',\n",
       " 'ay',\n",
       " 'er',\n",
       " 'ay',\n",
       " 'er',\n",
       " 'sil']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pre = defaultdict(list)\n",
    "for key,value in Data.items():\n",
    "    for v in value:\n",
    "        if len(Pre[key])==0 or Pre[key][-1]!= v:\n",
    "            Pre[key].append(v)\n",
    "            \n",
    "Pre['fjmg0_sx11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': 'a',\n",
       " 'ae': 'b',\n",
       " 'ah': 'c',\n",
       " 'ao': 'd',\n",
       " 'aw': 'e',\n",
       " 'ax': 'f',\n",
       " 'ay': 'g',\n",
       " 'b': 'h',\n",
       " 'ch': 'i',\n",
       " 'cl': 'j',\n",
       " 'd': 'k',\n",
       " 'dh': 'l',\n",
       " 'dx': 'm',\n",
       " 'eh': 'n',\n",
       " 'el': 'o',\n",
       " 'en': 'p',\n",
       " 'epi': 'q',\n",
       " 'er': 'r',\n",
       " 'ey': 's',\n",
       " 'f': 't',\n",
       " 'g': 'u',\n",
       " 'hh': 'v',\n",
       " 'ih': 'w',\n",
       " 'ix': 'x',\n",
       " 'iy': 'y',\n",
       " 'jh': 'z',\n",
       " 'k': 'A',\n",
       " 'l': 'B',\n",
       " 'm': 'C',\n",
       " 'n': 'D',\n",
       " 'ng': 'E',\n",
       " 'ow': 'F',\n",
       " 'oy': 'G',\n",
       " 'p': 'H',\n",
       " 'r': 'I',\n",
       " 's': 'J',\n",
       " 'sh': 'K',\n",
       " 'sil': 'L',\n",
       " 't': 'M',\n",
       " 'th': 'N',\n",
       " 'uh': 'O',\n",
       " 'uw': 'P',\n",
       " 'v': 'Q',\n",
       " 'vcl': 'R',\n",
       " 'w': 'S',\n",
       " 'y': 'T',\n",
       " 'z': 'U',\n",
       " 'zh': 'V'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = open('48_idx_chr.map_b')\n",
    "mapp = M.readlines()\n",
    "M.close()\n",
    "\n",
    "Map = {}\n",
    "for line in mapp:\n",
    "    line = line.strip().split(' ')\n",
    "    word,_ = line[0].split('\\t')\n",
    "    Map[word] = line[-1]\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('V1.csv','w',newline='')\n",
    "write = csv.writer(csvfile, delimiter=',')\n",
    "write.writerow(['id','phone_sequence'])\n",
    "\n",
    "for i in range(len(Number)):\n",
    "    S = ''\n",
    "    for word in Pre[Number[i]]:\n",
    "        S = S + Map[word]\n",
    "    write.writerow([Number[i],S])\n",
    "    \n",
    "len(Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RNN\n",
    "import theano as th\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import time\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.16549387e-09,   4.94554309e-09,   4.16883328e-09,\n",
       "          2.02587458e-09,   1.77389925e-09,   5.46537464e-08,\n",
       "          7.98637956e-09,   3.22530354e-07,   4.30052047e-08,\n",
       "          1.98693465e-06,   1.35180733e-06,   2.14694140e-07,\n",
       "          1.17137122e-09,   1.00542408e-09,   7.05283526e-07,\n",
       "          2.52535304e-09,   3.52990668e-07,   9.70481011e-08,\n",
       "          1.00348414e-08,   4.40698277e-05,   5.38683098e-10,\n",
       "          7.23425870e-08,   2.02923611e-09,   2.86660153e-08,\n",
       "          1.76082409e-07,   6.49708909e-08,   5.85485331e-08,\n",
       "          7.07270260e-07,   5.31050492e-09,   8.28954860e-09,\n",
       "          1.19729915e-08,   2.53382160e-09,   2.50886728e-10,\n",
       "          5.51583639e-07,   9.95084193e-09,   1.02518143e-07,\n",
       "          9.99917090e-01,   1.86282559e-05,   8.51631467e-06,\n",
       "          1.53132180e-06,   2.47269916e-09,   2.17976726e-09,\n",
       "          1.35107086e-07,   1.52865653e-07,   2.89487190e-08,\n",
       "          9.35259070e-09,   1.57907498e-09,   2.87901366e-06], dtype=float32),\n",
       " 'faem0_si1392_2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = np.load('prob_t.npz')\n",
    "Data = Data[Data.files[0]]\n",
    "F = np.load('TrainID.npz')\n",
    "TrainID = F[F.files[0]][0]\n",
    "\n",
    "Data[1],TrainID[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the label data as a dictionary\n",
    "Label = {}\n",
    "Y = open('train.lab')\n",
    "for line in Y:\n",
    "    line = line.strip().split(',')\n",
    "    Label[line[0]] = line[1]\n",
    "Y.close()\n",
    "\n",
    "#The map from labels to integers(To compute y_hat) \n",
    "lab_index = dict([['aa', 0], ['ae', 1], ['ah', 2], ['ao', 3], ['aw', 4], ['ax', 5], ['ay', 6], ['b', 7], ['ch', 8], \n",
    "               ['cl', 9], ['d', 10], ['dh', 11], ['dx', 12], ['eh', 13], ['el', 14], ['en', 15], ['epi', 16], \n",
    "               ['er', 17], ['ey', 18], ['f', 19], ['g', 20], ['hh', 21], ['ih', 22], ['ix', 23], ['iy', 24], \n",
    "               ['jh', 25], ['k', 26], ['l', 27], ['m', 28], ['ng', 29], ['n', 30], ['ow', 31], ['oy', 32], ['p', 33], \n",
    "               ['r', 34], ['sh', 35], ['sil', 36], ['s', 37], ['th', 38], ['t', 39], ['uh', 40], ['uw', 41], ['vcl', 42],\n",
    "               ['v', 43], ['w', 44], ['y', 45], ['zh', 46], ['z', 47]])\n",
    "\n",
    "def memo(f): \n",
    "    \"\"\"Memoization decorator, Used to accelerate the retrieval\"\"\"\n",
    "    cache = {}\n",
    "    def _f(*args):\n",
    "        try:\n",
    "            return cache[args]\n",
    "        except KeyError:\n",
    "            cache[args] = result = f(*args)\n",
    "            return result\n",
    "        except TypeError: #Some elements of args unhashable\n",
    "            return f(args)\n",
    "    _f.cache = cache\n",
    "    return _f\n",
    "\n",
    "@memo\n",
    "def y_hat(i):\n",
    "    \"\"\"give the np array of y_hat\"\"\"\n",
    "    l = np.zeros(48,dtype=np.float32)\n",
    "    l[lab_index[Label[TrainID[i]]]] = 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 474, 'faem0_si1392')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "Dat = defaultdict(list)\n",
    "Y_hat = defaultdict(list)\n",
    "Number = {}\n",
    "\n",
    "n = 0; old = ''\n",
    "for i in range(len(Data)):\n",
    "    ID = '_'.join(TrainID[i].split('_')[:2])\n",
    "    Dat[ID].append(Data[i])\n",
    "    Y_hat[ID].append(y_hat(i))\n",
    "    if ID != old:\n",
    "        Number[n] = ID\n",
    "        n += 1\n",
    "        old = ID\n",
    "        \n",
    "len(Dat['faem0_si1392']),len(Y_hat['faem0_si1392']), Number[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 90)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = T.tensor3()\n",
    "y_hat = T.tensor3()\n",
    "ind = T.vector()\n",
    "\n",
    "cons = 0.6\n",
    "a_0 = th.shared(np.zeros((777,48)))\n",
    "y_0 = th.shared(cons*np.random.randn(48))\n",
    "Wi = th.shared(cons*np.random.randn(48,48))\n",
    "Wh = th.shared(cons*np.random.randn(48,48))\n",
    "Wo = th.shared(cons*np.random.randn(96,48))\n",
    "bh = th.shared(cons*np.random.randn(48))\n",
    "bo = th.shared(cons*np.random.randn(48))\n",
    "\n",
    "def Update(para,grad):\n",
    "    \"\"\"theano update auxiliary function\"\"\"\n",
    "    return [(para[ix], para[ix]+Direction(ix,grad[ix])) for ix in range(len(grad))]\n",
    "\n",
    "Momentum = {}\n",
    "def Direction(ix,grad):\n",
    "    \"\"\"Compute the update\"\"\"\n",
    "    try:\n",
    "        Momentum[ix] = update = 0.95*Momentum[ix] - 0.001*grad\n",
    "        return update\n",
    "    except:\n",
    "        Momentum[ix] = update = -0.001*grad\n",
    "        return update\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+T.exp(-Z))\n",
    "\n",
    "def Softmax(y_pre,ind):\n",
    "    y_pre = T.exp(y_pre)\n",
    "    th.scan(softmax, sequences=[y_pre]) #Bottleneck\n",
    "    return (z.T/T.sum(z,axis=1)).T\n",
    "\n",
    "def step(Z_t,af_tm1):\n",
    "    af_t = sigmoid( zf_t + T.dot(af_tm1,Wh) + bh.dimshuffle('x',0) )\n",
    "    return af_t\n",
    "\n",
    "Z_seq = T.tensordot(x_seq,Wi,axes=[[2],[0]])\n",
    "Z_seq = Z_seq.dimshuffle(1,0,2)\n",
    "#z_seq = T.dot(x_seq,Wi)\n",
    "a_seq,_ = th.scan(step, sequences = Z_seq, \n",
    "                               outputs_info = [a_0],\n",
    "                              truncate_gradient=-1)\n",
    "\n",
    "#a_seq = T.concatenate([af_seq,ab_seq[::-1]],axis=1)\n",
    "y_pre = T.tensordot(a_seq,Wo)+bo.dimshuffle('x',0)\n",
    "y_seq = Softmax(y_pre.dimshuffle(1,0,2),ind)\n",
    "\n",
    "forword = th.function(inputs=[x_seq],outputs=y_seq)\n",
    "\n",
    "cost = T.sum((y_seq-y_hat)**2)\n",
    "parameters = [Wh,Wo,Wi,bh,bo]\n",
    "grads = T.grad(cost,parameters)\n",
    "rnn_train = th.function(inputs=[x_seq,y_hat,ind],outputs=cost,\n",
    "                       updates=Update(parameters,grads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edit(r,h):\n",
    "    r = r.split()\n",
    "    h = h.split()\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "                if i == 0:\n",
    "                        d[0][j] = j\n",
    "                elif j == 0:\n",
    "                        d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "            for j in range(1, len(h)+1):\n",
    "                    if r[i-1] == h[j-1]:\n",
    "                        d[i][j] = d[i-1][j-1]\n",
    "                    else:\n",
    "                        substitution = d[i-1][j-1] + 1\n",
    "                        insertion    = d[i][j-1] + 1\n",
    "                        deletion     = d[i-1][j] + 1\n",
    "                        d[i][j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    #edit distance\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "edit(\"a a a a a b c\",\"a a a c d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Order = np.random.permutation(len(Number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L w D c l O L H O L J n L A J c D c L k a B r U D J n D M J L h s J w J L'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VY = {}\n",
    "def Valid_Y():\n",
    "    try:\n",
    "        return VY[0]\n",
    "    except:\n",
    "        Y_V = []\n",
    "        for i in range(3200,len(Number)):\n",
    "            Y_V.append(Y_hat[Number[Order[i]]])\n",
    "\n",
    "        Y_val = []\n",
    "        for i in range(len(Y_V)):\n",
    "            yv =[]\n",
    "            for l in range(len(Y_V[i])):\n",
    "                yv.append(mapping[Map_label(np.argmax(Y_V[i][l]))])\n",
    "            Y_val.append(yv)\n",
    "\n",
    "        YV_set = defaultdict(list)\n",
    "        for key,F in enumerate(Y_val):\n",
    "            for f in F:\n",
    "                if len(YV_set[key])==0 or YV_set[key][-1]!= f:\n",
    "                    YV_set[key].append(f)            \n",
    "\n",
    "        YVal_set = []\n",
    "        for i in range(len(YV_set)):\n",
    "            U = ''\n",
    "            for k in range(len(YV_set[i])):\n",
    "                U = U + Map[YV_set[i][k]]+' '\n",
    "            YVal_set.append(U[:-1])\n",
    "        VY[0] = YVal_set\n",
    "        return YVal_set\n",
    "\n",
    "Valid_Y()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = 1\n",
    "\n",
    "x_seq = T.fmatrix()\n",
    "y_hat = T.fmatrix()\n",
    "ind = T.scalar()\n",
    "\n",
    "cons = 0.6\n",
    "a_0 = th.shared(cons*np.random.randn(48))\n",
    "y_0 = th.shared(cons*np.random.randn(48))\n",
    "Wi = th.shared(np.identity(48))#cons*np.random.randn(48,48))\n",
    "Wh = th.shared(np.identity(48))#cons*np.random.randn(48,48))\n",
    "Wo = th.shared(np.concatenate([np.identity(48),np.identity(48)]))#cons*np.random.randn(96,48))\n",
    "bh = th.shared(cons*np.random.randn(48))\n",
    "bo = th.shared(cons*np.random.randn(48))\n",
    "\n",
    "\n",
    "def Update(para,grad,ind):\n",
    "    \"\"\"theano update auxiliary function\"\"\"\n",
    "    return [(para[ix], para[ix]+Direction(ix,grad[ix],ind)) for ix in range(len(grad))]\n",
    "\n",
    "Temp_grad = defaultdict()\n",
    "def Cumulate(ix,grad,ind):\n",
    "    err = ifelse(T.le(ind,0),0,1)\n",
    "    try:\n",
    "        Temp_grad[ix] = Temp_grad[ix]*err + grad\n",
    "    except:\n",
    "        Temp_grad[ix] = grad\n",
    "    return grad*0\n",
    "    \n",
    "Momentum = {}\n",
    "def Direction(ix,grad,ind):\n",
    "    \"\"\"Compute the update\"\"\"\n",
    "    return ifelse(T.lt(ind,b-1),Cumulate(ix,grad,ind),Moment(ix,grad))\n",
    "\n",
    "def Moment(ix,grad):\n",
    "    grad = (Temp_grad[ix] + grad)/b\n",
    "    try:\n",
    "        Momentum[ix] = update = 0.95*Momentum[ix] - 0.001*grad\n",
    "        return update\n",
    "    except:\n",
    "        Momentum[ix] = update = -0.001*grad\n",
    "        return update\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+T.exp(-Z))\n",
    "\n",
    "def softmax(Z):\n",
    "    z = T.exp(Z)\n",
    "    return (z.T/T.sum(z,axis=1)).T\n",
    "\n",
    "def step(zf_t,zb_t,af_tm1,ab_tm1):\n",
    "    af_t = sigmoid( zf_t + T.dot(af_tm1,Wh) + bh )\n",
    "    ab_t = sigmoid( zb_t + T.dot(ab_tm1,Wh) + bh )\n",
    "    return af_t, ab_t\n",
    "\n",
    "z_seq = T.dot(x_seq,Wi)\n",
    "[af_seq,ab_seq],_ = th.scan(step, sequences = [z_seq,z_seq[::-1]], \n",
    "                               outputs_info = [a_0,a_0],\n",
    "                              truncate_gradient=-1)\n",
    "\n",
    "a_seq = T.concatenate([af_seq,ab_seq[::-1]],axis=1)\n",
    "y_pre = T.dot(a_seq,Wo)+bo.dimshuffle('x',0)\n",
    "y_seq = softmax(y_pre)\n",
    "\n",
    "forword = th.function(inputs=[x_seq],outputs=y_seq)\n",
    "\n",
    "cost = T.sum((y_seq-y_hat)**2)*ind/ind\n",
    "parameters = [Wh,Wo,Wi,bh,bo]\n",
    "grads = T.grad(cost,parameters)\n",
    "rnn_train = th.function(inputs=[x_seq,y_hat,ind],outputs=cost,\n",
    "                       updates=Update(parameters,grads,ind))\n",
    "\n",
    "def Validation():\n",
    "    Valid = []\n",
    "    for i in range(3200,len(Number)):\n",
    "        Valid.append(forword(Dat[Number[Order[i]]]))\n",
    "\n",
    "    Val = []\n",
    "    for i in range(len(Valid)):\n",
    "        v = []; yv =[]\n",
    "        for l in range(len(Valid[i])):\n",
    "            v.append(mapping[Map_label(np.argmax(Valid[i][l]))])\n",
    "        Val.append(v)\n",
    "\n",
    "    V_set = defaultdict(list)\n",
    "    for key,F in enumerate(Val):\n",
    "        for f in F:\n",
    "            if len(V_set[key])==0 or V_set[key][-1]!= f:\n",
    "                V_set[key].append(f)   \n",
    "\n",
    "    Val_set = [];\n",
    "    for i in range(len(V_set)):\n",
    "        S = ''\n",
    "        for k in range(len(V_set[i])):\n",
    "            S = S + Map[V_set[i][k]]+' '\n",
    "        Val_set.append(S[:-1])\n",
    "        \n",
    "    YVal_set = Valid_Y()\n",
    "    return np.mean([edit(Val_set[i],YVal_set[i]) for i in range(len(Val_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.328346\n",
      "13.9495967742\n",
      "Cost: 0.322396\n",
      "13.1794354839\n",
      "Cost: 0.317017\n",
      "13.0806451613\n",
      "Cost: 0.313502\n",
      "12.5745967742\n",
      "Cost 0.313502, using 130.826581 seconds\n",
      "Cost: 0.298910\n",
      "12.2983870968\n",
      "Cost: 0.295855\n",
      "12.0705645161\n",
      "Cost: 0.293212\n",
      "11.8387096774\n",
      "Cost: 0.290700\n",
      "11.7298387097\n",
      "Cost 0.290700, using 258.339715 seconds\n"
     ]
    }
   ],
   "source": [
    "def Permutate(n):\n",
    "    \"\"\"Auxiliary function for making batch of each epoch\"\"\"\n",
    "    s = np.random.permutation(n)\n",
    "    for i in range(n):\n",
    "        yield s[i] \n",
    "        \n",
    "st = time.clock()\n",
    "for j in range(2):\n",
    "    C = 0\n",
    "    N = 0\n",
    "    batch = 0\n",
    "    V = Permutate(3200)\n",
    "    for i in range(3200):\n",
    "        index = next(V)\n",
    "        C += rnn_train(Dat[Number[Order[index]]],Y_hat[Number[Order[index]]],batch)\n",
    "        N += len(Dat[Number[Order[index]]])\n",
    "        if i%800 == 799:\n",
    "            print('Cost: %f'%(C/N))\n",
    "            val = Validation()\n",
    "            print(val)\n",
    "            if val <= 11:\n",
    "                break\n",
    "        #batch = batch+1 if batch != (b-1) else 0\n",
    "\n",
    "    print('Cost %f, using %f seconds'%(C/N,time.clock()-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  61.,  61.,  10.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = T.matrix()\n",
    "resu,_ = th.scan(lambda a,b: T.dot(a,b),sequences=[A,A[::-1]])\n",
    "f = th.function(inputs=[A],outputs=resu)\n",
    "\n",
    "f([[1,2,3],[9,2,3],[6,2,1],[4,3,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  1.        ,  1.5       ],\n",
       "       [ 3.        ,  0.66666667,  1.        ],\n",
       "       [ 1.5       ,  0.5       ,  0.25      ],\n",
       "       [ 0.8       ,  0.6       ,  0.        ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = T.matrix()\n",
    "B = T.vector()\n",
    "F = th.function(inputs=[A,B],outputs = (A.T/B).T)\n",
    "\n",
    "F([[1,2,3],[9,2,3],[6,2,1],[4,3,0]],[2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -5.,  11.,  30.,  12.,   9.],\n",
       "        [ -2.,  28.,  60.,  32.,  14.]],\n",
       "\n",
       "       [[-12.,  25.,  72.,  30.,  20.],\n",
       "        [  8.,  43.,  24.,   0.,  30.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = T.tensor3()\n",
    "B = T.matrix()\n",
    "c = T.tensordot(A,B,axes=[[2],[0]])\n",
    "\n",
    "F = th.function(inputs=[A,B],outputs = c)\n",
    "\n",
    "F([[[3,1,2],[4,2,6]],[[7,2,5],[3,8,1]]],[[-3,0,6,1,2],[2,5,0,-1,3],[1,3,6,5,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.,  1.,  2.],\n",
       "        [ 7.,  2.,  5.],\n",
       "        [ 7.,  2.,  5.],\n",
       "        [ 7.,  2.,  5.]],\n",
       "\n",
       "       [[ 4.,  2.,  6.],\n",
       "        [ 3.,  8.,  1.],\n",
       "        [ 3.,  8.,  1.],\n",
       "        [ 3.,  8.,  1.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = T.tensor3()\n",
    "B = T.matrix()\n",
    "c = T.tensordot(A,B,axes=[[2],[0]])\n",
    "\n",
    "F = th.function(inputs=[A],outputs = A.dimshuffle(1,0,2))\n",
    "\n",
    "F([[[3,1,2],[4,2,6]],[[7,2,5],[3,8,1]],[[7,2,5],[3,8,1]],[[7,2,5],[3,8,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(156.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = T.tensor3()\n",
    "\n",
    "B = T.scalar()\n",
    "if T.lt(B,39):\n",
    "    r = B*4\n",
    "else:\n",
    "    r = B\n",
    "ff = th.function(inputs=[B],outputs=r)\n",
    "ff(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fadg0_si1279', 'fadg0_si1279_1', 180)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = np.load('prob.out.npz')\n",
    "Test = Test[Test.files[0]]\n",
    "TID = np.load('TestID.npz')\n",
    "TestID = TID[TID.files[0]][0]\n",
    "\n",
    "TestD = defaultdict(list)\n",
    "Test_Num = {}\n",
    "\n",
    "n = 0; old = ''\n",
    "for i in range(len(Test)):\n",
    "    ID = '_'.join(TestID[i].split('_')[:2])\n",
    "    TestD[ID].append(Test[i])\n",
    "    if ID != old:\n",
    "        Test_Num[n] = ID\n",
    "        n += 1\n",
    "        old = ID\n",
    "        \n",
    "Test_Num[0],TestID[0],len(TestD[Test_Num[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(len(Test_Num)):\n",
    "    prediction.append(forword(TestD[Test_Num[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mapp = open('48_39.map')\n",
    "mapp = Mapp.readlines()\n",
    "Mapp.close()\n",
    "\n",
    "def Map_label(n):\n",
    "    for key,val in lab_index.items():\n",
    "        if val == n:\n",
    "            return key\n",
    "    print(\"Worng!\")\n",
    "\n",
    "mapping = {}\n",
    "for line in mapp:\n",
    "    line = line.strip().split('\\t')\n",
    "    mapping[line[0]] = line[1]\n",
    "\n",
    "M = open('48_idx_chr.map_b')\n",
    "mapp = M.readlines()\n",
    "M.close()\n",
    "\n",
    "Map = {}\n",
    "for line in mapp:\n",
    "    line = line.strip().split(' ')\n",
    "    word,_ = line[0].split('\\t')\n",
    "    Map[word] = line[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'eh',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'ch',\n",
       " 'ch',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'ng',\n",
       " 'ng',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'p',\n",
       " 'p',\n",
       " 'b',\n",
       " 'b',\n",
       " 'p',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'd',\n",
       " 'b',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'v',\n",
       " 'v',\n",
       " 'v',\n",
       " 'jh',\n",
       " 'jh',\n",
       " 'jh',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final = []\n",
    "for i in range(len(prediction)):\n",
    "    p = []\n",
    "    for l in prediction[i]:\n",
    "        p.append(mapping[Map_label(np.argmax(l))])\n",
    "    Final.append(p) \n",
    "\n",
    "Final[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'ae',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'ch',\n",
       " 'ch',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ey',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'ng',\n",
       " 'ng',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 'uw',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'ow',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'p',\n",
       " 'p',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'iy',\n",
       " 'v',\n",
       " 'v',\n",
       " 'v',\n",
       " 'jh',\n",
       " 'jh',\n",
       " 'jh',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'dh',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'ih',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'sh',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'er',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil',\n",
       " 'sil']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decide(value,i):\n",
    "    if value[i-1] == value[i+1]:\n",
    "        return True\n",
    "    elif value[i]!= value[i+1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "for j,F in enumerate(Final):\n",
    "    for i in range(1,len(F)-1):\n",
    "        if decide(F,i) and F[i]!= F[i-1]:\n",
    "            F[i] = F[i-1]\n",
    "    Final[j] = F\n",
    "    \n",
    "Final[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'f',\n",
       " 'ae',\n",
       " 'sil',\n",
       " 'ch',\n",
       " 'sh',\n",
       " 'ey',\n",
       " 'ow',\n",
       " 'uw',\n",
       " 'sil',\n",
       " 'd',\n",
       " 'ih',\n",
       " 'n',\n",
       " 'ng',\n",
       " 'l',\n",
       " 'uw',\n",
       " 's',\n",
       " 'w',\n",
       " 'r',\n",
       " 'ih',\n",
       " 'ow',\n",
       " 'z',\n",
       " 's',\n",
       " 'sil',\n",
       " 'p',\n",
       " 'b',\n",
       " 'ih',\n",
       " 'sil',\n",
       " 'iy',\n",
       " 'v',\n",
       " 'jh',\n",
       " 'f',\n",
       " 'dh',\n",
       " 'ih',\n",
       " 'sh',\n",
       " 'er',\n",
       " 'sil']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pre = defaultdict(list)\n",
    "for key,F in enumerate(Final):\n",
    "    for f in F:\n",
    "        if len(Pre[key])==0 or Pre[key][-1]!= f:\n",
    "            Pre[key].append(f)\n",
    "            \n",
    "Pre[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test_Num[0]\n",
    "import csv\n",
    "csvfile = open('V2.csv','w',newline='')\n",
    "write = csv.writer(csvfile, delimiter=',')\n",
    "write.writerow(['id','phone_sequence'])\n",
    "\n",
    "for i in range(len(Test_Num)):\n",
    "    S = ''\n",
    "    for word in Pre[i]:\n",
    "        S = S + Map[word]\n",
    "    write.writerow([Test_Num[i],S])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 592)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Test_Num),len(Pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.identity(4),np.identity(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
